#!/usr/bin/env python3
import os
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"

import torch
import time
import sys

def main():
    # Parse GPU ID from command line
    if len(sys.argv) != 2:
        print("Usage: python a100-load.py <gpu_id>")
        print("Example: python a100-load.py 1")
        sys.exit(1)

    try:
        gpu_id = int(sys.argv[1])
    except ValueError:
        print("Error: GPU ID must be an integer.")
        sys.exit(1)

    if not torch.cuda.is_available():
        print("CUDA is not available. Is the NVIDIA driver installed?")
        sys.exit(1)

    if gpu_id >= torch.cuda.device_count():
        print(f"Error: GPU {gpu_id} does not exist. Only {torch.cuda.device_count()} GPU(s) found.")
        sys.exit(1)

    # Set device
    device = torch.device(f'cuda:{gpu_id}')
    print(f'Using device: {torch.cuda.get_device_name(device)} (GPU {gpu_id})')

    # Allocate large tensors
    print(f'Starting 5-minute compute load on GPU {gpu_id}...')
    a = torch.randn(8000, 8000, device=device)
    b = torch.randn(8000, 8000, device=device)

    # Warm up
    torch.mm(a, b)
    torch.cuda.synchronize()

    # Run load for 5 minutes
    start_time = time.time()
    duration = 21600  # seconds (5 minutes)

    while (time.time() - start_time) < duration:
        c = torch.mm(a, b)
        torch.cuda.synchronize()  # Ensure GPU stays busy
        elapsed = int(time.time() - start_time)
        if elapsed % 10 == 0:  # Print every 10 seconds
            print(f'  GPU {gpu_id} load: {elapsed:3d}s / {duration}s')


if __name__ == "__main__":
    main()
